@page "/"
@using KristofferStrube.Blazor.DOM
@using KristofferStrube.Blazor.FileAPI
@using KristofferStrube.Blazor.MediaCaptureStreams
@using KristofferStrube.Blazor.WebAudio
@using KristofferStrube.Blazor.WebIDL.Exceptions
@inject IJSRuntime JSRuntime
@inject IMediaDevicesService MediaDevicesService;
@implements IAsyncDisposable

<PageTitle>Blazor.MediaStreamRecording - Recording</PageTitle>

@if (error is not null)
{
    <code>@error</code>
}
else if (mediaStream is null)
{
    <button class="btn btn-success" @onclick="Open">Open Microphone</button>
}
else if (recorder is null)
{
    <svg class="bi" viewBox="0 0 16 16" height="60">
        <g @onclick="StartRecording" style="cursor:pointer">
            <title>Start Recording</title>
            <circle stroke="black" stroke-width="0" fill="#B61C1C" cx="8" cy="4" r="2"></circle>
            <circle stroke="black" stroke-width="0" fill="#B61C1C" cx="8" cy="8" r="2"></circle>
            <rect stroke="black" stroke-width="0" fill="#B61C1C" x="6" y="4" width="4" height="4"></rect>
            <path stroke="#B61C1C" stroke-width="1.5" fill="none" d="M 4 8 C 4 13 12 13 12 8" stroke-linecap="round"></path>
            <line stroke="#B61C1C" stroke-width="1.5" x1="8" y1="13" x2="8" y2="12" stroke-linecap="round"></line>
            <circle stroke="#B61C1C" stroke-width="1" fill="transparent" cx="8" cy="8" r="7"></circle>
        </g>
    </svg>
    <AmplitudePlot Analyser="liveAnalyzer" />
}
else if (audioBuffer is null)
{
    <svg class="bi" viewBox="0 0 16 16" height="60">
        <g @onclick="StopRecording" style="cursor:pointer">
            <title>Stop Recording</title>
            <circle stroke="#212121" stroke-width="1" fill="transparent" cx="8" cy="8" r="7"></circle>
            <rect stroke="#212121" stroke-width="1" fill="#212121" x="9" y="4" width="2" height="8" stroke-linejoin="round" stroke-linecap="round"></rect>
            <rect stroke="#212121" stroke-width="1" fill="#212121" x="5" y="4" width="2" height="8" stroke-linejoin="round" stroke-linecap="round"></rect>
        </g>
    </svg>
    <AmplitudePlot Analyser="liveAnalyzer" Color="#F00" />
}
else if (audioSourceNode is null)
{
    <svg class="bi" viewBox="0 0 16 16" height="60">
        <g @onclick="PlayRecording" style="cursor:pointer">
            <title>Play Recording</title>
            <circle stroke="#B61C1C" stroke-width="1" fill="transparent" cx="8" cy="8" r="7"></circle>
            <polygon stroke="#B61C1C" stroke-width="1" fill="#B61C1C" points="6,4 12,8 6,12" stroke-linecap="round" stroke-linejoin="round"></polygon>
        </g>
    </svg>
}
else
{
    <svg class="bi" viewBox="0 0 16 16" height="60">
        <g @onclick="StopPlayingRecording" style="cursor:pointer">
            <title>
                Stop Playing Recording
            </title>
            <circle stroke="#B61C1C" stroke-width="1" fill="transparent" cx="8" cy="8" r="7"></circle>
            <rect stroke="#B61C1C" stroke-width="1" fill="#B61C1C" x="5" y="5" width="6" height="6" stroke-linejoin="round"></rect>
        </g>
    </svg>
    <AmplitudePlot Analyser="bufferAnalyzer" />
}

@code {
    private string? error;
    MediaStream? mediaStream;
    MediaStreamAudioSourceNode? liveSourceNoce;
    AnalyserNode? liveAnalyzer;

    MediaRecorder? recorder;
    EventListener<BlobEvent>? dataAvailableEventListener;
    AudioBuffer? audioBuffer;
    List<Blob> blobsRecorded = new();
    AudioContext? context;
    AudioBufferSourceNode? audioSourceNode;
    AnalyserNode? bufferAnalyzer;

    private async Task Open()
    {
        try
        {
            MediaDevices mediaDevices = await MediaDevicesService.GetMediaDevicesAsync();
            mediaStream = await mediaDevices.GetUserMediaAsync(new MediaStreamConstraints() { Audio = true });

            context = await AudioContext.CreateAsync(JSRuntime);

            MediaStreamAudioSourceOptions options = new()
                {
                    MediaStream = mediaStream
                };
            liveSourceNoce = await MediaStreamAudioSourceNode.CreateAsync(JSRuntime, context, options);
            liveAnalyzer = await AnalyserNode.CreateAsync(JSRuntime, context);
            await liveSourceNoce.ConnectAsync(liveAnalyzer);
        }
        catch (WebIDLException ex)
        {
            error = $"{ex.GetType().Name}: {ex.Message}";
        }
    }

    private async Task StartRecording()
    {
        if (mediaStream is null) return;

        recorder = await MediaRecorder.CreateAsync(JSRuntime, mediaStream);

        dataAvailableEventListener = await EventListener<BlobEvent>.CreateAsync(JSRuntime, async (BlobEvent e) =>
        {
            Blob blob = await e.GetDataAsync();
            blobsRecorded.Add(blob);
        });
        await recorder.AddOnDataAvailableEventListenerAsync(dataAvailableEventListener);

        await recorder.StartAsync();
    }

    private async Task StopRecording()
    {
        if (mediaStream is null || recorder is null || dataAvailableEventListener is null || context is null) return;

        try
        {
            MediaStreamTrack[] audioTracks = await mediaStream.GetAudioTracksAsync();
            foreach (MediaStreamTrack track in audioTracks)
            {
                await track.StopAsync();
                await track.DisposeAsync();
            }

            await recorder.StopAsync();
            await recorder.RemoveOnDataAvailableEventListenerAsync(dataAvailableEventListener);
            await dataAvailableEventListener.DisposeAsync();
            await recorder.DisposeAsync();

            Blob combinedBlob = await Blob.CreateAsync(JSRuntime, [.. blobsRecorded] );

            byte[] audioData = await combinedBlob.ArrayBufferAsync();
            audioBuffer = await context.DecodeAudioDataAsync(audioData);
        }
        catch (WebIDLException ex)
        {
            error = $"{ex.GetType().Name}: {ex.Message}";
        }
    }

    private async Task PlayRecording()
    {
        if (context is null || audioBuffer is null) return;

        await using AudioDestinationNode destination = await context.GetDestinationAsync();

        audioSourceNode = await AudioBufferSourceNode.CreateAsync(
            JSRuntime,
            context,
            new() { Buffer = audioBuffer, Loop = true }
        );

        await audioSourceNode.ConnectAsync(destination);

        bufferAnalyzer = await AnalyserNode.CreateAsync(JSRuntime, context);
        await audioSourceNode.ConnectAsync(bufferAnalyzer);

        await audioSourceNode.StartAsync();
    }

    private async Task StopPlayingRecording()
    {
        if (mediaStream is not null)
        {
            await mediaStream.DisposeAsync();
            mediaStream = null;
        }
        if (recorder is not null)
        {
            await recorder.DisposeAsync();
            recorder = null;
        }
        if (audioBuffer is not null)
        {
            await audioBuffer.DisposeAsync();
            audioBuffer = null;
        }
        blobsRecorded.Clear();
        if (context is not null)
        {
            await context.DisposeAsync();
            context = null;
        }
        if (audioSourceNode is not null)
        {
            await audioSourceNode.DisconnectAsync();
            await audioSourceNode.DisposeAsync();
            audioSourceNode = null;
        }
    }

    public async ValueTask DisposeAsync()
    {
        await StopPlayingRecording();
    }
}